{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "import pykalman as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clean GPS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date      Time  Latitude  Longitude  Speed  TrackAngle\n",
      "6938  2023-04-20  00:00:00   58.3098    15.1327   2.42      340.11\n",
      "6939  2023-04-20  00:00:01   58.3098    15.1327   2.90      336.39\n",
      "6940  2023-04-20  00:00:02   58.3098    15.1326   3.53      348.29\n",
      "6941  2023-04-20  00:00:03   58.3099    15.1326   4.02      345.83\n",
      "6942  2023-04-20  00:00:04   58.3099    15.1326   4.54      343.28\n",
      "...          ...       ...       ...        ...    ...         ...\n",
      "83740 2023-04-20  21:59:08   59.5635    17.8822   0.66      286.10\n",
      "83741 2023-04-20  21:59:09   59.5635    17.8822   0.24      286.10\n",
      "83742 2023-04-20  21:59:10   59.5635    17.8822   0.21      286.10\n",
      "83743 2023-04-20  21:59:11   59.5635    17.8822   1.39      286.10\n",
      "83744 2023-04-20  21:59:12   59.5635    17.8822   0.05      286.10\n",
      "\n",
      "[76807 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the GPS data from the .log file\n",
    "data_gps1 = pd.read_csv('./Data/1/gps/gps_2023-04-20.log', sep=';')\n",
    "\n",
    "# Data cleaning and formatting\n",
    "data_gps1['Latitude'] = data_gps1['Latitude'].str.rstrip('N').astype(float)\n",
    "data_gps1['Longitude'] = data_gps1['Longitude'].str.rstrip('E').astype(float)\n",
    "data_gps1['Date'] = pd.to_datetime(data_gps1['Date'], format='%d/%m/%Y')\n",
    "data_gps1['Time'] = pd.to_datetime(data_gps1['Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Drop MagenticVariation column as it is not relevant to the problem\n",
    "data_gps1.drop(columns=['MagneticVariation'], inplace=True)\n",
    "\n",
    "# Filter rows where the date is '2023-04-20'\n",
    "data_gps1 = data_gps1[data_gps1['Date'] == '2023-04-20']\n",
    "\n",
    "print(data_gps1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "                      Date      Latitude     Longitude         Speed  \\\n",
      "count                76807  76807.000000  76807.000000  76807.000000   \n",
      "mean   2023-04-20 00:00:00     59.456417     17.416823      8.643521   \n",
      "min    2023-04-20 00:00:00     56.903300     14.561400      0.000000   \n",
      "25%    2023-04-20 00:00:00     59.402400     16.505200      0.260000   \n",
      "50%    2023-04-20 00:00:00     59.563400     17.882000      0.470000   \n",
      "75%    2023-04-20 00:00:00     59.563500     17.882100      1.000000   \n",
      "max    2023-04-20 00:00:00     59.655000     17.927000     55.920000   \n",
      "std                    NaN      0.261189      0.725303     17.414235   \n",
      "\n",
      "         TrackAngle  \n",
      "count  76807.000000  \n",
      "mean     170.024356  \n",
      "min        0.000000  \n",
      "25%       72.460000  \n",
      "50%      142.770000  \n",
      "75%      287.450000  \n",
      "max      359.990000  \n",
      "std      113.454766  \n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(data_gps1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as GPSSet1Data.csv in the CleanDataFolder.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "data_gps1.to_csv('./CleanData/GPSSet1Data.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved as GPSSet1Data.csv in the CleanDataFolder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clean Shock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date      Time    AccelX    AccelY     AccelZ     GyroX  \\\n",
      "0        1970-01-01  00:28:01 -0.599752  0.065531  10.419545 -0.013439   \n",
      "1        1970-01-01  00:28:01 -0.069945  0.000499  10.019079 -0.023518   \n",
      "2        1970-01-01  00:28:01 -0.445631 -0.054700   9.785857 -0.022907   \n",
      "3        1970-01-01  00:28:01 -0.442073 -0.130693   9.712997  0.000916   \n",
      "4        1970-01-01  00:28:01 -0.094992  0.030634   9.786232  0.016799   \n",
      "...             ...       ...       ...       ...        ...       ...   \n",
      "1898344  1970-01-01  00:28:02  0.069265 -0.064725   9.843576 -0.000305   \n",
      "1898345  1970-01-01  00:28:02  0.067974 -0.063557   9.842454 -0.000305   \n",
      "1898346  1970-01-01  00:28:02  0.070460 -0.067118   9.843538  0.000000   \n",
      "1898347  1970-01-01  00:28:02  0.065394 -0.063613   9.840264 -0.000305   \n",
      "1898348  1970-01-01  00:28:02  0.065498 -0.069564   9.841603  0.000000   \n",
      "\n",
      "            GyroY     GyroZ  Temperature  \n",
      "0       -0.003665 -0.005803         29.0  \n",
      "1        0.004581 -0.007636         29.0  \n",
      "2       -0.002138 -0.007330         29.0  \n",
      "3       -0.001833 -0.007025         29.0  \n",
      "4        0.000916 -0.006720         29.0  \n",
      "...           ...       ...          ...  \n",
      "1898344 -0.002138 -0.006109         30.0  \n",
      "1898345 -0.002138 -0.006109         30.0  \n",
      "1898346 -0.002138 -0.006109         30.0  \n",
      "1898347 -0.002138 -0.006109         30.0  \n",
      "1898348 -0.002443 -0.006109         30.0  \n",
      "\n",
      "[1898349 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Shock data\n",
    "data_shock1 = pd.read_csv('./Data/1/shock/shock_2023-04-20.log', sep=';', header=None)\n",
    "\n",
    "# Add column headers\n",
    "data_shock1.columns = ['Timestamp', 'AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ', 'Temperature']\n",
    "\n",
    "# Convert timestamp to datetime format\n",
    "data_shock1['Timestamp'] = pd.to_datetime(data_shock1['Timestamp'], unit='ns')\n",
    "\n",
    "# Extract Date and Time from Timestamp\n",
    "data_shock1['Date'] = data_shock1['Timestamp'].dt.date\n",
    "data_shock1['Time'] = data_shock1['Timestamp'].dt.strftime('%H:%M:%S')  # Format time as hh:mm:ss\n",
    "\n",
    "# Drop the original Timestamp column\n",
    "data_shock1.drop(columns=['Timestamp'], inplace=True)\n",
    "\n",
    "# Reorder the columns (optional)\n",
    "data_shock1 = data_shock1[['Date', 'Time', 'AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ', 'Temperature']]\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data_shock1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             AccelX        AccelY        AccelZ         GyroX         GyroY  \\\n",
      "count  1.898349e+06  1.898349e+06  1.898349e+06  1.898349e+06  1.898349e+06   \n",
      "mean   3.285397e-02 -5.813003e-02  9.845792e+00 -4.584672e-05 -2.074417e-03   \n",
      "std    5.863487e-01  1.581588e-01  2.549591e-01  3.810172e-02  6.528746e-03   \n",
      "min   -8.219378e+00 -3.059698e+00 -1.007930e-01 -5.778790e-01 -1.505780e-01   \n",
      "25%   -1.202300e-02 -6.370400e-02  9.837987e+00 -3.050000e-04 -2.443000e-03   \n",
      "50%    6.349500e-02 -5.995300e-02  9.841563e+00 -3.050000e-04 -2.138000e-03   \n",
      "75%    7.016000e-02 -5.045300e-02  9.846917e+00  0.000000e+00 -1.833000e-03   \n",
      "max    8.624488e+00  9.355698e+00  1.522790e+01  5.729920e-01  1.624900e-01   \n",
      "\n",
      "              GyroZ   Temperature  \n",
      "count  1.898349e+06  1.898346e+06  \n",
      "mean  -6.253358e-03  2.893846e+01  \n",
      "std    3.031473e-02  4.929150e+00  \n",
      "min   -3.512470e-01  1.900000e+01  \n",
      "25%   -6.414000e-03  2.400000e+01  \n",
      "50%   -6.109000e-03  3.100000e+01  \n",
      "75%   -6.109000e-03  3.300000e+01  \n",
      "max    2.200000e+01  3.500000e+01  \n"
     ]
    }
   ],
   "source": [
    "print(data_shock1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date      Time    AccelX    AccelY     AccelZ     GyroX  \\\n",
      "0       2023-04-20  00:28:01 -0.599752  0.065531  10.419545 -0.013439   \n",
      "1       2023-04-20  00:28:01 -0.069945  0.000499  10.019079 -0.023518   \n",
      "2       2023-04-20  00:28:01 -0.445631 -0.054700   9.785857 -0.022907   \n",
      "3       2023-04-20  00:28:01 -0.442073 -0.130693   9.712997  0.000916   \n",
      "4       2023-04-20  00:28:01 -0.094992  0.030634   9.786232  0.016799   \n",
      "...            ...       ...       ...       ...        ...       ...   \n",
      "1898344 2023-04-20  00:28:02  0.069265 -0.064725   9.843576 -0.000305   \n",
      "1898345 2023-04-20  00:28:02  0.067974 -0.063557   9.842454 -0.000305   \n",
      "1898346 2023-04-20  00:28:02  0.070460 -0.067118   9.843538  0.000000   \n",
      "1898347 2023-04-20  00:28:02  0.065394 -0.063613   9.840264 -0.000305   \n",
      "1898348 2023-04-20  00:28:02  0.065498 -0.069564   9.841603  0.000000   \n",
      "\n",
      "            GyroY     GyroZ  Temperature  \n",
      "0       -0.003665 -0.005803         29.0  \n",
      "1        0.004581 -0.007636         29.0  \n",
      "2       -0.002138 -0.007330         29.0  \n",
      "3       -0.001833 -0.007025         29.0  \n",
      "4        0.000916 -0.006720         29.0  \n",
      "...           ...       ...          ...  \n",
      "1898344 -0.002138 -0.006109         30.0  \n",
      "1898345 -0.002138 -0.006109         30.0  \n",
      "1898346 -0.002138 -0.006109         30.0  \n",
      "1898347 -0.002138 -0.006109         30.0  \n",
      "1898348 -0.002443 -0.006109         30.0  \n",
      "\n",
      "[1898349 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Note: From this data we can observe that shock data record year is 1970. And GPS Data record date is 2023. It doesnot make sense.\n",
    "# Hence converting the date to 2023-04-20\n",
    "\n",
    "# Convert '1970-01-01' to '2023-04-20'\n",
    "data_shock1['Date'] = data_shock1['Date'].apply(lambda x: x + pd.DateOffset(days=19467))\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data_shock1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as ShockSet1Data.csv in the CleanDataFolder.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "data_shock1.to_csv('./CleanData/ShockSet1Data.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved as ShockSet1Data.csv in the CleanDataFolder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.06 TiB for an array with shape (145806491643,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# GPS data set 1 merged with shock data set 1 on basis of 'Date' and 'Time'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_combined \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(data_gps1, data_shock1, on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m], how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minner\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(data_combined)\n",
      "File \u001b[1;32md:\\MyWorkspace\\ShockSensorAnalysis\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    148\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32md:\\MyWorkspace\\ShockSensorAnalysis\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:809\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n\u001b[0;32m    807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m--> 809\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_info()\n\u001b[0;32m    811\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    813\u001b[0m )\n\u001b[0;32m    814\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32md:\\MyWorkspace\\ShockSensorAnalysis\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1065\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     join_index, right_indexer, left_indexer \u001b[39m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1062\u001b[0m         right_ax, left_ax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys, sort\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort\n\u001b[0;32m   1063\u001b[0m     )\n\u001b[0;32m   1064\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1065\u001b[0m     (left_indexer, right_indexer) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_indexers()\n\u001b[0;32m   1067\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[0;32m   1068\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\MyWorkspace\\ShockSensorAnalysis\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1038\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_join_indexers\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]]:\n\u001b[0;32m   1037\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m     \u001b[39mreturn\u001b[39;00m get_join_indexers(\n\u001b[0;32m   1039\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, how\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow\n\u001b[0;32m   1040\u001b[0m     )\n",
      "File \u001b[1;32md:\\MyWorkspace\\ShockSensorAnalysis\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1690\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1680\u001b[0m join_func \u001b[39m=\u001b[39m {\n\u001b[0;32m   1681\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m: libjoin\u001b[39m.\u001b[39minner_join,\n\u001b[0;32m   1682\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m: libjoin\u001b[39m.\u001b[39mleft_outer_join,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m: libjoin\u001b[39m.\u001b[39mfull_outer_join,\n\u001b[0;32m   1687\u001b[0m }[how]\n\u001b[0;32m   1689\u001b[0m \u001b[39m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[1;32m-> 1690\u001b[0m \u001b[39mreturn\u001b[39;00m join_func(lkey, rkey, count, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\MyWorkspace\\ShockSensorAnalysis\\venv\\lib\\site-packages\\pandas\\_libs\\join.pyx:48\u001b[0m, in \u001b[0;36mpandas._libs.join.inner_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.06 TiB for an array with shape (145806491643,) and data type int64"
     ]
    }
   ],
   "source": [
    "# GPS data set 1 merged with shock data set 1 on basis of 'Date' and 'Time'\n",
    "data_combined = pd.merge(data_gps1, data_shock1, on=['Date', 'Time'], how='inner')\n",
    "print(data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
